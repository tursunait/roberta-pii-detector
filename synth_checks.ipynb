{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c5e1b01",
   "metadata": {},
   "source": [
    "# Check 1: Verify Variable Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca4e492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üìä SEQUENCE LENGTH STATISTICS\n",
      "==================================================\n",
      "\n",
      "üîπ TRAIN SET:\n",
      "  Min length: 5\n",
      "  Max length: 223\n",
      "  Average: 54.0\n",
      "  Median: 31.0\n",
      "  Std Dev: 47.0\n",
      "\n",
      "üîπ VAL SET:\n",
      "  Min length: 6\n",
      "  Max length: 223\n",
      "  Average: 54.1\n",
      "\n",
      "üîπ TEST SET:\n",
      "  Min length: 6\n",
      "  Max length: 213\n",
      "  Average: 53.8\n",
      "\n",
      "‚úÖ GOOD: Found 216 different sequence lengths\n",
      "   Range: 5 to 223 tokens\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "train = load_from_disk(\"data/processed/train\")\n",
    "val = load_from_disk(\"data/processed/val\")\n",
    "test = load_from_disk(\"data/processed/test\")\n",
    "\n",
    "# Get all input_ids lengths\n",
    "train_lengths = [len(ex['input_ids']) for ex in train]\n",
    "val_lengths = [len(ex['input_ids']) for ex in val]\n",
    "test_lengths = [len(ex['input_ids']) for ex in test]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"üìä SEQUENCE LENGTH STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nüîπ TRAIN SET:\")\n",
    "print(f\"  Min length: {min(train_lengths)}\")\n",
    "print(f\"  Max length: {max(train_lengths)}\")\n",
    "print(f\"  Average: {np.mean(train_lengths):.1f}\")\n",
    "print(f\"  Median: {np.median(train_lengths):.1f}\")\n",
    "print(f\"  Std Dev: {np.std(train_lengths):.1f}\")\n",
    "\n",
    "print(\"\\nüîπ VAL SET:\")\n",
    "print(f\"  Min length: {min(val_lengths)}\")\n",
    "print(f\"  Max length: {max(val_lengths)}\")\n",
    "print(f\"  Average: {np.mean(val_lengths):.1f}\")\n",
    "\n",
    "print(\"\\nüîπ TEST SET:\")\n",
    "print(f\"  Min length: {min(test_lengths)}\")\n",
    "print(f\"  Max length: {max(test_lengths)}\")\n",
    "print(f\"  Average: {np.mean(test_lengths):.1f}\")\n",
    "\n",
    "# Check if all sequences are the same length (BAD)\n",
    "if len(set(train_lengths)) == 1:\n",
    "    print(\"\\n‚ùå WARNING: All sequences are the SAME length!\")\n",
    "    print(f\"   All sequences are {train_lengths[0]} tokens\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ GOOD: Found {len(set(train_lengths))} different sequence lengths\")\n",
    "    print(f\"   Range: {min(train_lengths)} to {max(train_lengths)} tokens\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac6d14",
   "metadata": {},
   "source": [
    "# Check 2: Analyze Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2047651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä DETAILED SEQUENCE LENGTH ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üìà Basic Statistics:\n",
      "   Total examples: 96000\n",
      "   Min length: 5\n",
      "   Max length: 223\n",
      "   Average: 54.0\n",
      "   Median: 31.0\n",
      "   Std Dev: 47.0\n",
      "   Unique lengths: 216\n",
      "\n",
      "üìä Length Distribution:\n",
      "   Very Short   (  0- 50):  59663 ( 62.1%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Short        ( 50-100):  18885 ( 19.7%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Medium       (100-150):  11204 ( 11.7%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Long         (150-200):   6122 (  6.4%) ‚ñà‚ñà‚ñà\n",
      "   Very Long    (200-300):    126 (  0.1%) \n",
      "   Extra Long   (300-600):      0 (  0.0%) \n",
      "\n",
      "üî¢ Top 10 Most Common Lengths:\n",
      "    25 tokens:  2502 times ( 2.61%)\n",
      "    22 tokens:  2487 times ( 2.59%)\n",
      "    24 tokens:  2445 times ( 2.55%)\n",
      "    23 tokens:  2438 times ( 2.54%)\n",
      "    21 tokens:  2330 times ( 2.43%)\n",
      "    20 tokens:  2290 times ( 2.39%)\n",
      "    12 tokens:  2289 times ( 2.38%)\n",
      "    27 tokens:  2198 times ( 2.29%)\n",
      "    26 tokens:  2197 times ( 2.29%)\n",
      "    19 tokens:  2165 times ( 2.26%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä DETAILED SEQUENCE LENGTH ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get lengths\n",
    "train_lengths = [len(ex['input_ids']) for ex in train]\n",
    "\n",
    "# Basic stats\n",
    "print(f\"\\nüìà Basic Statistics:\")\n",
    "print(f\"   Total examples: {len(train_lengths)}\")\n",
    "print(f\"   Min length: {min(train_lengths)}\")\n",
    "print(f\"   Max length: {max(train_lengths)}\")\n",
    "print(f\"   Average: {np.mean(train_lengths):.1f}\")\n",
    "print(f\"   Median: {np.median(train_lengths):.1f}\")\n",
    "print(f\"   Std Dev: {np.std(train_lengths):.1f}\")\n",
    "print(f\"   Unique lengths: {len(set(train_lengths))}\")\n",
    "\n",
    "# Distribution buckets\n",
    "print(f\"\\nüìä Length Distribution:\")\n",
    "buckets = [\n",
    "    (0, 50, \"Very Short\"),\n",
    "    (50, 100, \"Short\"),\n",
    "    (100, 150, \"Medium\"),\n",
    "    (150, 200, \"Long\"),\n",
    "    (200, 300, \"Very Long\"),\n",
    "    (300, 600, \"Extra Long\")\n",
    "]\n",
    "\n",
    "for min_len, max_len, label in buckets:\n",
    "    count = sum(1 for l in train_lengths if min_len <= l < max_len)\n",
    "    pct = count / len(train_lengths) * 100\n",
    "    bar = \"‚ñà\" * int(pct / 2)  # Visual bar\n",
    "    print(f\"   {label:12} ({min_len:3}-{max_len:3}): {count:6} ({pct:5.1f}%) {bar}\")\n",
    "\n",
    "# Most common lengths\n",
    "print(f\"\\nüî¢ Top 10 Most Common Lengths:\")\n",
    "length_counts = Counter(train_lengths)\n",
    "for length, count in length_counts.most_common(10):\n",
    "    pct = count / len(train_lengths) * 100\n",
    "    print(f\"   {length:3} tokens: {count:5} times ({pct:5.2f}%)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a14f9",
   "metadata": {},
   "source": [
    "# Check 3: Sample Examples with Different Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e7d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìù SAMPLE EXAMPLES (Different Lengths)\n",
      "==================================================\n",
      "\n",
      "üîπ SHORT Example (Index 632):\n",
      "   Length: 5 tokens\n",
      "   Text: Ref 317299...\n",
      "\n",
      "üîπ MEDIUM Example (Index 47015):\n",
      "   Length: 31 tokens\n",
      "   Text: Ship no Unit 0131 Box 8486, DPO AE 09091 for Michael Brooks from Wilson PLC by 1980-11-26O...\n",
      "\n",
      "üîπ LONG Example (Index 52168):\n",
      "   Length: 223 tokens\n",
      "   Text: SSN: 308-28-3803; Phone:Y9 4 1 3 5 1 6 5 8 5 3 5 0g Email: jeffreywillis@exampoe.lom. SSn: 669-51-8018; Phone: 1 9 8 6 8 9 3 0 7 1 1 0 2 6 5; Email: nicholas29(at)example.com. yO snyone know how to co...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Show examples of different lengths\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üìù SAMPLE EXAMPLES (Different Lengths)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get examples with different lengths\n",
    "sorted_train = sorted(enumerate(train), key=lambda x: len(x[1]['input_ids']))\n",
    "\n",
    "# Short example\n",
    "short_idx, short_ex = sorted_train[0]\n",
    "print(f\"\\nüîπ SHORT Example (Index {short_idx}):\")\n",
    "print(f\"   Length: {len(short_ex['input_ids'])} tokens\")\n",
    "print(f\"   Text: {short_ex['text'][:200]}...\")\n",
    "\n",
    "# Medium example\n",
    "mid_idx, mid_ex = sorted_train[len(sorted_train)//2]\n",
    "print(f\"\\nüîπ MEDIUM Example (Index {mid_idx}):\")\n",
    "print(f\"   Length: {len(mid_ex['input_ids'])} tokens\")\n",
    "print(f\"   Text: {mid_ex['text'][:200]}...\")\n",
    "\n",
    "# Long example\n",
    "long_idx, long_ex = sorted_train[-1]\n",
    "print(f\"\\nüîπ LONG Example (Index {long_idx}):\")\n",
    "print(f\"   Length: {len(long_ex['input_ids'])} tokens\")\n",
    "print(f\"   Text: {long_ex['text'][:200]}...\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe19733",
   "metadata": {},
   "source": [
    "# Check 4: Verify No Padding Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f7258c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üîç CHECKING FOR PADDING TOKENS\n",
      "====================================================================================================\n",
      "‚úÖ GOOD: No padding tokens found in the dataset!\n",
      "   Padding will be handled dynamically by DataCollator during training.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check if there are padding tokens in the data\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"üîç CHECKING FOR PADDING TOKENS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "pad_token_id = 0  # RoBERTa's padding token\n",
    "\n",
    "has_padding = False\n",
    "for i, ex in enumerate(train):\n",
    "    if pad_token_id in ex['input_ids']:\n",
    "        has_padding = True\n",
    "        print(f\"‚ùå Found padding in example {i}\")\n",
    "        print(f\"   Input IDs: {ex['input_ids']}\")\n",
    "        break\n",
    "\n",
    "if not has_padding:\n",
    "    print(\"‚úÖ GOOD: No padding tokens found in the dataset!\")\n",
    "    print(\"   Padding will be handled dynamically by DataCollator during training.\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b99153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'contact Info: Olivia Hernandez, jcannon@example.org, 001 278 67080566809', 'spans': [{'end': 30, 'label': 'PERSON', 'start': 14}, {'end': 51, 'label': 'EMAIL', 'start': 32}, {'end': 72, 'label': 'PHONE', 'start': 53}], 'input_ids': [1, 32233, 17883, 35, 11924, 7816, 6, 1236, 438, 17375, 1039, 46781, 4, 1957, 6, 16273, 134, 37481, 38679, 34249, 4280, 36621, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 17, 19, 0, 1, 2, 2, 2, 2, 2, 3, 0, 5, 6, 6, 6, 6, 6, 7, -100], 'tokens': ['[CLS]', 'contact', 'ƒ†Info', ':', 'ƒ†Olivia', 'ƒ†Hernandez', ',', 'ƒ†j', 'c', 'annon', '@', 'example', '.', 'org', ',', 'ƒ†00', '1', 'ƒ†278', 'ƒ†670', '805', '66', '809', '[SEP]']}\n"
     ]
    }
   ],
   "source": [
    "ex = train[0]\n",
    "assert len(ex[\"input_ids\"]) == len(ex[\"attention_mask\"]) == len(ex[\"labels\"])\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab14659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checks passed!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/processed/label2id.json\") as f:\n",
    "    label2id = json.load(f)\n",
    "max_label_id = max(label2id.values())\n",
    "assert max(ex[\"labels\"]) <= max_label_id\n",
    "print(\"All checks passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
